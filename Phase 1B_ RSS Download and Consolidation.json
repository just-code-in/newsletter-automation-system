{
  "name": "Phase 1B: RSS Download and Consolidation",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "triggerAtHour": 6,
              "triggerAtMinute": 45
            }
          ]
        }
      },
      "id": "0ddad229-c12b-41f0-aa75-2d598e59de4e",
      "name": "Weekly Newsletter Trigger",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.1,
      "position": [
        -2864,
        16
      ]
    },
    {
      "parameters": {},
      "id": "84c80b34-015f-45cd-9c6e-ba7cd0dc4efb",
      "name": "Manual Trigger (Testing/Override)",
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -2864,
        192
      ]
    },
    {
      "parameters": {
        "jsCode": "// Check for manual override date parameter\nconst manualDate = $input.all()[0]?.json?.override_date;\nconst today = new Date().toISOString().split('T')[0];\n\nreturn [{\n  json: {\n    current_date: today,\n    override_date: manualDate || null,\n    tracking_file_key: 'newsletter-automation-last-run.json'\n  }\n}];"
      },
      "id": "3126bd99-1965-48b9-9fd4-df884716b4f6",
      "name": "Initialize Date Processing",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2416,
        112
      ]
    },
    {
      "parameters": {
        "bucketName": "n8n-ai-news-stories",
        "fileKey": "={{ $json.tracking_file_key }}"
      },
      "id": "960ab9f3-bc6a-4863-946e-5bbd81d10b79",
      "name": "Fetch Last Run Tracking",
      "type": "n8n-nodes-base.s3",
      "typeVersion": 1,
      "position": [
        -2208,
        112
      ],
      "credentials": {
        "s3": {
          "id": "WRnQEZaYQvFm8YY3",
          "name": "Cloudflare R2 S3 Format Datalake"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse tracking file or create default\nlet trackingData;\ntry {\n  const inputData = $input.first();\n  console.log('Input data keys:', Object.keys(inputData));\n  \n  // Try different data sources\n  if (inputData.binary && inputData.binary.data) {\n    console.log('Parsing from binary.data');\n    const binaryContent = inputData.binary.data;\n    if (typeof binaryContent === 'string') {\n      trackingData = JSON.parse(binaryContent);\n    } else if (binaryContent.data) {\n      // Handle Base64 encoded JSON\n      trackingData = JSON.parse(Buffer.from(binaryContent.data, 'base64').toString('utf8'));\n    } else {\n      trackingData = JSON.parse(binaryContent.toString());\n    }\n  } else if (inputData.json && typeof inputData.json === 'object' && inputData.json.last_processed_date !== undefined) {\n    console.log('Using data from json field directly');\n    trackingData = inputData.json;\n  } else {\n    throw new Error('No valid tracking data structure found');\n  }\n  console.log('Successfully parsed tracking data:', JSON.stringify(trackingData, null, 2));\n} catch (error) {\n  console.log('Error parsing tracking data:', error.message);\n  console.log('Input data structure:', JSON.stringify($input.first(), null, 2));\n  // First run - create default tracking\n  trackingData = {\n    last_successful_run: null,\n    last_processed_date: null,\n    files_processed: 0,\n    workflow_version: \"1.0\"\n  };\n}\n\nconst currentDate = $('Initialize Date Processing').first().json.current_date;\nconst overrideDate = $('Initialize Date Processing').first().json.override_date;\n\n// Calculate start date\nlet startDate;\nif (overrideDate) {\n  startDate = overrideDate;\n} else if (trackingData.last_processed_date) {\n  // Start from day after last processed\n  const lastDate = new Date(trackingData.last_processed_date);\n  lastDate.setDate(lastDate.getDate() + 1);\n  const calculatedStart = lastDate.toISOString().split('T')[0];\n  \n  // If calculated start date is in the future, process today instead\n  if (calculatedStart > currentDate) {\n    console.log(`Calculated start date ${calculatedStart} is in future, using current date ${currentDate}`);\n    startDate = currentDate;\n  } else {\n    startDate = calculatedStart;\n  }\n} else {\n  // First run - start from today\n  startDate = currentDate;\n}\n\n// Generate date prefixes to scan\nconst datePrefixes = [];\nconst start = new Date(startDate);\nconst end = new Date(currentDate);\n\nfor (let d = new Date(start); d <= end; d.setDate(d.getDate() + 1)) {\n  datePrefixes.push(d.toISOString().split('T')[0]);\n}\n\n// Debug logging\nconsole.log('Date Range Calculation:');\nconsole.log(`  Last processed date: ${trackingData.last_processed_date}`);\nconsole.log(`  Current date: ${currentDate}`);\nconsole.log(`  Calculated start date: ${startDate}`);\nconsole.log(`  Date prefixes to process: ${JSON.stringify(datePrefixes)}`);\n\nreturn [{\n  json: {\n    tracking_data: trackingData,\n    current_date: currentDate,\n    start_date: startDate,\n    date_prefixes: datePrefixes,\n    dates_to_process: datePrefixes.length\n  }\n}];"
      },
      "id": "228186a6-3f67-42ef-9a8d-70fb5e1e9867",
      "name": "Calculate Date Range",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1984,
        112
      ]
    },
    {
      "parameters": {
        "fieldToSplitOut": "date_prefixes",
        "options": {}
      },
      "id": "a416e258-47e3-4930-a1d2-f32ab176d7f5",
      "name": "Split Date Prefixes",
      "type": "n8n-nodes-base.itemLists",
      "typeVersion": 3,
      "position": [
        -1760,
        112
      ]
    },
    {
      "parameters": {
        "resource": "bucket",
        "operation": "search",
        "bucketName": "n8n-ai-news-stories",
        "additionalFields": {}
      },
      "id": "3b60499e-f84c-47a5-b8e8-f0109e6558e9",
      "name": "List Files by Date",
      "type": "n8n-nodes-base.s3",
      "typeVersion": 1,
      "position": [
        -1536,
        112
      ],
      "credentials": {
        "s3": {
          "id": "WRnQEZaYQvFm8YY3",
          "name": "Cloudflare R2 S3 Format Datalake"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Filter for .md files and extract metadata from bucket search results\nconst items = $input.all();\nconst mdFiles = [];\nconst targetDates = $('Calculate Date Range').first().json.date_prefixes;\n\nconsole.log(`Filter & Parse: Looking for files with target dates: ${targetDates.join(', ')}`);\nconsole.log(`Filter & Parse: Processing ${items.length} S3 search result items`);\n\nfor (const item of items) {\n  // Handle different possible data structures from bucket search\n  let files = [];\n  \n  // Check various possible response formats\n  if (item.json.Contents) {\n    files = item.json.Contents;\n  } else if (item.json.objects) {\n    files = item.json.objects;\n  } else if (item.json.files) {\n    files = item.json.files;\n  } else if (Array.isArray(item.json)) {\n    files = item.json;\n  } else if (item.json.Key) {\n    // Single file object\n    files = [item.json];\n  }\n  \n  console.log(`Processing ${files.length} files from S3 search result`);\n  \n  for (const file of files) {\n    // Get the key/name from various possible fields\n    const key = file.Key || file.key || file.name || file.Key;\n    \n    if (key && key.endsWith('.md')) {\n      // Parse key format: YYYY-MM-DD/title.source.md\n      const parts = key.split('/');\n      if (parts.length === 2) {\n        const date = parts[0];\n        const filename = parts[1];\n        const nameParts = filename.replace('.md', '').split('.');\n        \n        if (nameParts.length >= 2) {\n          const source = nameParts[nameParts.length - 1];\n          const titleSlug = nameParts.slice(0, -1).join('.');\n          \n          mdFiles.push({\n            key: key,\n            date: date,\n            title_slug: titleSlug,\n            source: source,\n            size: file.Size || file.size || 0,\n            last_modified: file.LastModified || file.lastModified || new Date().toISOString()\n          });\n        }\n      }\n    }\n  }\n}\n\n// Sort by date and source for consistent processing\nmdFiles.sort((a, b) => {\n  if (a.date !== b.date) return a.date.localeCompare(b.date);\n  return a.source.localeCompare(b.source);\n});\n\nconsole.log(`Filter & Parse: Found ${mdFiles.length} .md files total`);\nconsole.log(`Filter & Parse: Dates found: ${[...new Set(mdFiles.map(f => f.date))].join(', ')}`);\nconsole.log(`Filter & Parse: Files matching target dates: ${mdFiles.filter(f => targetDates.includes(f.date)).length}`);\n\nreturn mdFiles.map(file => ({ json: file }));"
      },
      "id": "316c65b0-0710-484e-8f0a-09e12b18b615",
      "name": "Filter & Parse Markdown Files",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1328,
        112
      ]
    },
    {
      "parameters": {
        "jsCode": "// Filter markdown files to only include dates within the calculated range and deduplicate\nconst mdFiles = $input.all();\nconst dateRange = $('Calculate Date Range').first().json.date_prefixes;\n\nconst filteredFiles = [];\nconst seenFiles = new Set();\n\nfor (const fileItem of mdFiles) {\n  const file = fileItem.json;\n  \n  // Check if the file's date is within our target date range\n  if (dateRange.includes(file.date)) {\n    // Use file key as unique identifier to prevent duplicates\n    const fileKey = file.key;\n    if (!seenFiles.has(fileKey)) {\n      seenFiles.add(fileKey);\n      filteredFiles.push(file);\n    }\n  }\n}\n\n// Log filtering results for debugging\nconsole.log(`Date range filter: ${dateRange.length} target dates, ${mdFiles.length} total files, ${filteredFiles.length} files after filtering and deduplication`);\nconsole.log(`Target dates: ${dateRange.join(', ')}`);\nconsole.log(`Filtered files by date: ${filteredFiles.map(f => f.date).join(', ')}`);\nconsole.log(`Unique file keys: ${filteredFiles.map(f => f.key).join(', ')}`);\n\nreturn filteredFiles.map(file => ({ json: file }));"
      },
      "id": "date-range-filter-node-id",
      "name": "Filter Files by Date Range",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1216,
        112
      ]
    },
    {
      "parameters": {
        "bucketName": "n8n-ai-news-stories",
        "fileKey": "={{ $json.key }}"
      },
      "id": "27347230-ceed-4295-bd78-3ae970a6873e",
      "name": "Download Markdown Content",
      "type": "n8n-nodes-base.s3",
      "typeVersion": 1,
      "position": [
        -1104,
        112
      ],
      "credentials": {
        "s3": {
          "id": "WRnQEZaYQvFm8YY3",
          "name": "Cloudflare R2 S3 Format Datalake"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Extract markdown content, apply enhanced content cleaning, and combine with metadata\nconst items = $input.all();\nconst results = [];\n\n// STAGE 1 ENHANCED CONTENT CLEANING FUNCTIONS\n\n// 1. Remove advertisements, sponsorships, and promotional content\nfunction removeAdvertisements(content) {\n  return content\n    // Remove \"PRESENTED BY\" and \"FROM OUR PARTNERS\" sections (comprehensive)\n    .replace(/#{1,6}\\s*\\**(?:PRESENTED BY|FROM OUR PARTNERS).*?\\**/gim, '')\n    .replace(/\\*\\*(?:PRESENTED BY|FROM OUR PARTNERS).*?\\*\\*/gi, '')\n    .replace(/#{1,6}\\s*FROM OUR PARTNERS[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    // Remove sponsor blocks and acknowledgments\n    .replace(/sponsored by.*?(?=\\n|$)/gi, '')\n    .replace(/in partnership with.*?(?=\\n|$)/gi, '')\n    .replace(/\\*\\*sponsored.*?\\*\\*/gi, '')\n    .replace(/\\*\\*featured.*?\\*\\*/gi, '')\n    // Remove subscription and promotional sections\n    .replace(/\\[.*?browse.*?tools.*?\\]/gi, '')\n    .replace(/\\[.*?browse.*?courses.*?\\]/gi, '')\n    .replace(/\\[.*?advertise.*?\\]/gi, '')\n    .replace(/\\[.*?sponsorship.*?options.*?\\]/gi, '')\n    .replace(/\\[.*?book a call.*?\\]/gi, '')\n    // Remove promotional calls-to-action\n    .replace(/click here to.*?(?=\\n|$)/gi, '')\n    .replace(/sign up.*?(?=\\n|$)/gi, '')\n    .replace(/get started for free.*?(?=\\n|$)/gi, '')\n    .replace(/register today.*?(?=\\n|$)/gi, '')\n    .replace(/claim.*?credits.*?(?=\\n|$)/gi, '')\n    // Remove weekly spotlight and promotional sections\n    .replace(/#{1,6}\\s*Weekly Spotlight[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    .replace(/#{1,6}\\s*.*?Spotlight[\\s\\S]*?(?=#{1,6}|$)/gi, '');\n}\n\n// 2. Remove images and videos\nfunction removeMediaContent(content) {\n  return content\n    // Remove markdown images\n    .replace(/!\\[.*?\\]\\(.*?\\)/g, '')\n    // Remove HTML img tags\n    .replace(/<img[^>]*>/gi, '')\n    // Remove video embeds\n    .replace(/<video[^>]*>.*?<\\/video>/gis, '')\n    .replace(/\\[.*?video.*?\\]/gi, '')\n    .replace(/watch.*?here.*?\\[.*?\\]/gi, '')\n    // Remove image source references and captions\n    .replace(/image source:.*?(?=\\n|$)/gi, '')\n    .replace(/source:.*?(?=\\n|$)/gi, '');\n}\n\n// 3. Clean URLs (remove UTM parameters but preserve important links)\nfunction cleanUrls(content) {\n  return content\n    // Clean URLs in parentheses format (link) - remove everything after ?\n    .replace(/\\((https?:\\/\\/[^\\s\\)]+)\\?[^\\)]*\\)/g, '($1)')\n    // Clean URLs in markdown link format [text](url) - remove everything after ?\n    .replace(/\\[([^\\]]+)\\]\\((https?:\\/\\/[^\\s\\)]+)\\?[^\\)]*\\)/g, '[$1]($2)')\n    // Clean standalone URLs with UTM parameters\n    .replace(/(https?:\\/\\/[^\\s]+)\\?utm_[^\\s]*/g, '$1')\n    // Clean any other tracking parameters\n    .replace(/(https?:\\/\\/[^\\s]+)\\?[^\\s]*(?:utm_|ref=|track=|source=)[^\\s]*/g, '$1')\n    // Remove empty markdown links\n    .replace(/\\[\\]\\([^\\)]*\\)/g, '')\n    // Remove promotional/tracking URLs but preserve content URLs\n    .replace(/\\[.*?(?:advertise|sponsor|promote|track|analytics).*?\\]\\([^\\)]+\\)/gi, '')\n    .replace(/https?:\\/\\/[^\\s]*(?:advertise|sponsor|promote|track|analytics|utm_)[^\\s]*/gi, '');\n}\n\n// 4. Remove engagement content, polls, and interface elements\nfunction removeEngagementContent(content) {\n  return content\n    // Remove comprehensive poll patterns\n    .replace(/what did you think.*?\\?.*?(?=\\n|$)/gi, '')\n    .replace(/how.*?did.*?we.*?do.*?\\?.*?(?=\\n|$)/gi, '')\n    .replace(/rate this.*?(?=\\n|$)/gi, '')\n    .replace(/feedback.*?\\?.*?(?=\\n|$)/gi, '')\n    // Remove poll options with star ratings\n    .replace(/^\\s*-\\s*[^\\n]*⭐[^\\n]*$/gim, '')\n    .replace(/^\\s*-\\s*[^\\n]*🧠[^\\n]*$/gim, '')\n    .replace(/amazing.*?loved it.*?⭐.*?(?=\\n|$)/gi, '')\n    .replace(/terrible.*?⭐.*?(?=\\n|$)/gi, '')\n    .replace(/nailed it.*?⭐.*?(?=\\n|$)/gi, '')\n    // Remove login/subscribe prompts\n    .replace(/login.*?or.*?subscribe.*?to participate.*?(?=\\n|$)/gi, '')\n    .replace(/\\[login\\].*?\\[subscribe\\]/gi, '')\n    // Remove social engagement prompts\n    .replace(/share this.*?(?=\\n|$)/gi, '')\n    .replace(/follow us.*?(?=\\n|$)/gi, '')\n    // Remove \"Keep reading\" sections\n    .replace(/#{1,6}\\s*Keep reading[\\s\\S]*?$/gi, '')\n    .replace(/keep reading[\\s\\S]*?$/gi, '');\n}\n\n// 5. Remove ancillary content, navigation, and newsletter meta-content\nfunction removeAncillaryContent(content) {\n  return content\n    // Remove navigation elements\n    .replace(/view more.*?(?=\\n|$)/gi, '')\n    .replace(/twitter widget iframe/gi, '')\n    .replace(/read more.*?(?=\\n|$)/gi, '')\n    // Remove comprehensive \"In this issue\" patterns\n    .replace(/in this issue[:.]*[\\s\\S]*?(?=\\n#|$)/gi, '')\n    .replace(/^in this issue.*?(?=\\n|$)/gim, '')\n    .replace(/^\\*\\*in today.*?ai.*?\\*\\*[\\s\\S]*?(?=\\n#|$)/gim, '')\n    // Remove \"What's trending\" and similar sections\n    .replace(/#{1,6}\\s*What's trending[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    .replace(/#{1,6}\\s*.*?trending.*?social.*?headlines[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    // Remove repeated headlines (pattern: \"- Title # Title\")\n    .replace(/^-\\s*(.+?)\\s*#\\s*\\1\\s*$/gim, '# $1')\n    // Enhanced duplicate title removal - exact duplicates on consecutive lines\n    .replace(/^(.{10,})\\s*\\n+\\1\\s*$/gim, '$1')\n    // Remove duplicate titles with hash patterns (# Title\\nTitle)\n    .replace(/^#\\s*(.+?)\\s*\\n+\\1\\s*$/gim, '# $1')\n    // Remove table structures used for layout (non-data tables)\n    .replace(/\\|\\s*\\|\\s*\\|[\\s\\S]*?\\|\\s*$/gm, '')\n    .replace(/^\\s*\\|.*?\\|\\s*$/gm, '')\n    // Remove footer elements\n    .replace(/unsubscribe.*?(?=\\n|$)/gi, '')\n    .replace(/manage preferences.*?(?=\\n|$)/gi, '')\n    .replace(/until next time.*?(?=\\n|$)/gi, '')\n    .replace(/see you.*?soon.*?(?=\\n|$)/gi, '');\n}\n\n// 6. Remove author information and publication meta-data\nfunction removeAuthorInfo(content) {\n  return content\n    // Remove bylines and author attribution\n    .replace(/^by\\s+.*?(?=\\n|$)/gim, '')\n    .replace(/author:?\\s*.*?(?=\\n|$)/gi, '')\n    // Remove author images and social links\n    .replace(/\\[.*?author.*?\\]/gi, '')\n    .replace(/@\\w+/g, '')  // Remove @ mentions\n    // Remove publication dates with author names\n    .replace(/.*?\\d{4}.*?\\/.*?(?=\\n|$)/g, '')\n    // Remove team signatures and author attributions\n    .replace(/^.*?team$|team.*?(?=\\n|$)/gim, '')\n    .replace(/zain.*?kahn.*?(?=\\n|$)/gi, '')\n    .replace(/grant.*?harvey.*?(?=\\n|$)/gi, '')\n    .replace(/zach.*?mink.*?(?=\\n|$)/gi, '')\n    // Remove \"humans behind\" signatures\n    .replace(/the humans behind.*?(?=\\n|$)/gi, '')\n    .replace(/see you.*?(?=\\n|$)/gi, '');\n}\n\n// 7. Remove newsletter-specific patterns\nfunction removeNewsletterSpecificPatterns(content) {\n  return content\n    // Remove tool recommendation sections\n    .replace(/#{1,6}\\s*Hot Tools[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    .replace(/#{1,6}\\s*.*?tools.*?releases[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    .replace(/#{1,6}\\s*Deep Dives?[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    .replace(/#{1,6}\\s*Trending AI Tools[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    // Remove \"Whenever you're ready\" sections\n    .replace(/whenever you.*?ready.*?(?=\\n|$)/gi, '')\n    .replace(/when.*?ready.*?take.*?next.*?step.*?(?=\\n|$)/gi, '')\n    // Remove community and promotional sections\n    .replace(/#{1,6}\\s*Community[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    .replace(/#{1,6}\\s*.*?workflows?[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    // Remove trivia and game sections\n    .replace(/#{1,6}\\s*.*?Trivia[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    .replace(/#{1,6}\\s*.*?Commentary[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    // Remove productivity sections with tool lists\n    .replace(/#{1,6}\\s*Productivity[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    .replace(/#{1,6}\\s*.*?AI Tools.*?Productivity[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    // Remove academic/course promotional content\n    .replace(/#{1,6}\\s*.*?Academy[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    // Remove meme and social content\n    .replace(/meme of the day.*?(?=\\n|$)/gi, '')\n    .replace(/#{1,6}\\s*.*?meme.*?(?=#{1,6}|$)/gi, '')\n    // Remove \"Quick Hits\" and \"Everything else\" sections\n    .replace(/#{1,6}\\s*Quick Hits[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    .replace(/#{1,6}\\s*Everything else.*?today[\\s\\S]*?(?=#{1,6}|$)/gi, '')\n    // Remove \"Highlights\" and event sections\n    .replace(/#{1,6}\\s*Highlights.*?News.*?Guides.*?Events[\\s\\S]*?(?=#{1,6}|$)/gi, '');\n}\n\n// 8. Remove all emojis from content\nfunction removeEmojis(content) {\n  return content\n    // Remove all emoji characters (comprehensive Unicode ranges)\n    .replace(/[\\u{1F600}-\\u{1F64F}]/gu, '') // Emoticons\n    .replace(/[\\u{1F300}-\\u{1F5FF}]/gu, '') // Misc Symbols and Pictographs\n    .replace(/[\\u{1F680}-\\u{1F6FF}]/gu, '') // Transport and Map\n    .replace(/[\\u{1F1E0}-\\u{1F1FF}]/gu, '') // Regional country flags\n    .replace(/[\\u{2600}-\\u{26FF}]/gu, '')   // Misc symbols\n    .replace(/[\\u{2700}-\\u{27BF}]/gu, '')   // Dingbats\n    .replace(/[\\u{FE00}-\\u{FE0F}]/gu, '')   // Variation Selectors\n    .replace(/[\\u{1F900}-\\u{1F9FF}]/gu, '') // Supplemental Symbols and Pictographs\n    .replace(/[\\u{1F018}-\\u{1F270}]/gu, '') // Various asian characters\n    .replace(/[\\u{238C}\\u{2744}\\u{2764}]/gu, '') // Misc additional emojis\n    // Remove common emoji patterns\n    .replace(/⭐+/g, '')\n    .replace(/🔥+/g, '')\n    .replace(/🛠️+/g, '')\n    .replace(/🧠+/g, '')\n    .replace(/📧+/g, '')\n    .replace(/🚗+/g, '')\n    .replace(/🎤+/g, '')\n    .replace(/💫+/g, '')\n    .replace(/🌐+/g, '')\n    .replace(/📸+/g, '')\n    .replace(/🏗️+/g, '')\n    .replace(/💻+/g, '')\n    .replace(/🎯+/g, '')\n    .replace(/⚡+/g, '')\n    .replace(/✨+/g, '')\n    .replace(/👯+/g, '')\n    .replace(/📄+/g, '')\n    .replace(/🖼️+/g, '')\n    .replace(/📜+/g, '')\n    .replace(/🗣️+/g, '');\n}\n\n// 9. Clean excessive whitespace and formatting\nfunction normalizeWhitespace(content) {\n  return content\n    .replace(/\\n\\s*\\n\\s*\\n/g, '\\n\\n')  // Collapse multiple line breaks\n    .replace(/^\\s+|\\s+$/gm, '')         // Trim lines\n    .replace(/\\s+/g, ' ')              // Normalize spaces\n    .trim();\n}\n\n// MAIN PROCESSING LOOP\nfor (let i = 0; i < items.length; i++) {\n  const item = items[i];\n  let content = '';\n  \n  // The S3 download puts content in binary.data as a JSON object\n  if (item.binary && item.binary.data) {\n    try {\n      // Parse the JSON object from binary data\n      let binaryContent;\n      if (typeof item.binary.data === 'string') {\n        binaryContent = JSON.parse(item.binary.data);\n      } else {\n        binaryContent = item.binary.data;\n      }\n      \n      // Extract the Base64 data and decode it\n      if (binaryContent && binaryContent.data) {\n        content = Buffer.from(binaryContent.data, 'base64').toString('utf8');\n      }\n    } catch (error) {\n      // Fallback to string content if JSON parsing fails\n      if (Buffer.isBuffer(item.binary.data)) {\n        content = item.binary.data.toString('utf8');\n      } else if (typeof item.binary.data === 'string') {\n        content = item.binary.data;\n      }\n    }\n  }\n  \n  // APPLY ENHANCED CONTENT CLEANING PIPELINE\n  const originalLength = content.length;\n  \n  content = removeAdvertisements(content);\n  content = removeMediaContent(content);\n  content = cleanUrls(content);\n  content = removeEngagementContent(content);\n  content = removeAncillaryContent(content);\n  content = removeAuthorInfo(content);\n  content = removeNewsletterSpecificPatterns(content);\n  content = removeEmojis(content);\n  content = normalizeWhitespace(content);\n  \n  const cleanedLength = content.length;\n  const reductionPercentage = originalLength > 0 ? ((originalLength - cleanedLength) / originalLength * 100).toFixed(1) : 0;\n  \n  const metadata = item.json || {};\n  \n  // Clean up title from slug\n  const title = metadata.title_slug\n    ? metadata.title_slug.split('-').map(word => word.charAt(0).toUpperCase() + word.slice(1)).join(' ')\n    : `File ${i + 1}`;\n  \n  results.push({\n    ...metadata,\n    title: title,\n    content: content,\n    content_length: cleanedLength,\n    original_length: originalLength,\n    cleaning_reduction: `${reductionPercentage}%`,\n    word_count: content ? content.split(/\\s+/).filter(word => word.length > 0).length : 0\n  });\n}\n\nreturn results.map(result => ({ json: result }));"
      },
      "id": "a4173984-e6ad-43e2-be79-ae6ec3a6bda6",
      "name": "Parse Content & Metadata",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -880,
        112
      ]
    },
    {
      "parameters": {
        "aggregate": "aggregateAllItemData",
        "options": {}
      },
      "id": "f6b1638a-8a24-414f-8bb3-449728be0d39",
      "name": "Aggregate All Content",
      "type": "n8n-nodes-base.aggregate",
      "typeVersion": 1,
      "position": [
        -656,
        112
      ]
    },
    {
      "parameters": {
        "jsCode": "// Combine all articles into a structured markdown newsletter with single-date focus\nconst articles = $input.first().json.data;\n\n// STAGE 1.2: SINGLE-DATE CONTENT PROCESSING\n// Determine target date (most recent or current date)\nconst today = new Date().toISOString().split('T')[0];\n\n// Group articles by date and identify target date\nconst articlesByDate = {};\nfor (const article of articles) {\n  if (!articlesByDate[article.date]) {\n    articlesByDate[article.date] = [];\n  }\n  articlesByDate[article.date].push(article);\n}\n\nconst availableDates = Object.keys(articlesByDate).sort();\nconst targetDate = availableDates.includes(today) ? today : availableDates[availableDates.length - 1];\n\n// ONLY PROCESS ARTICLES FROM TARGET DATE\nconst targetArticles = articlesByDate[targetDate] || [];\n\n// Build combined markdown for single date only\nlet combinedMarkdown = '';\n\n// Header - always single date\ncombinedMarkdown += `# Daily Newsletter - ${targetDate}\\n\\n`;\n\n// Add processing note if date mismatch\nif (targetDate !== today) {\n  combinedMarkdown += `*Note: Processing newsletter for ${targetDate} (latest available content)*\\n\\n`;\n}\n\n// Content for target date only\nif (targetArticles.length > 0) {\n  combinedMarkdown += `## ${targetDate}\\n\\n`;\n  \n  for (const article of targetArticles) {\n    // Format source name nicely\n    const sourceName = article.source\n      .split('-')\n      .map(word => word.charAt(0).toUpperCase() + word.slice(1))\n      .join(' ');\n    \n    combinedMarkdown += `### ${article.title} (${sourceName})\\n\\n`;\n    combinedMarkdown += `${article.content}\\n\\n`;\n    \n    // Add cleaning statistics as comment for debugging\n    if (article.cleaning_reduction) {\n      combinedMarkdown += `<!-- Content cleaned: ${article.cleaning_reduction} reduction from ${article.original_length} chars -->\\n\\n`;\n    }\n    \n    combinedMarkdown += `---\\n\\n`;\n  }\n} else {\n  combinedMarkdown += `No articles available for ${targetDate}.\\n\\n`;\n}\n\n// Generate statistics for target date only\nconst totalArticles = targetArticles.length;\nconst totalWords = targetArticles.reduce((sum, article) => sum + article.word_count, 0);\nconst totalOriginalChars = targetArticles.reduce((sum, article) => sum + (article.original_length || 0), 0);\nconst totalCleanedChars = targetArticles.reduce((sum, article) => sum + article.content_length, 0);\nconst overallReduction = totalOriginalChars > 0 ? ((totalOriginalChars - totalCleanedChars) / totalOriginalChars * 100).toFixed(1) : 0;\nconst sources = [...new Set(targetArticles.map(a => a.source))];\n\n// Include all available dates for reference\nconst dateInfo = {\n  target_date: targetDate,\n  available_dates: availableDates,\n  date_selection_reason: targetDate === today ? 'current_date' : 'latest_available',\n  total_dates_available: availableDates.length,\n  skipped_dates: availableDates.filter(date => date !== targetDate)\n};\n\n// Ensure we have content to save - prevent Buffer undefined errors\nif (!combinedMarkdown || combinedMarkdown.trim().length === 0) {\n  combinedMarkdown = `# Daily Newsletter - ${targetDate}\\n\\nNo content available for processing.\\n\\nProcessing Date: ${new Date().toISOString()}\\nAvailable Dates: ${availableDates.join(', ')}\\nTarget Date: ${targetDate}\\n\\nThis may indicate an issue with data processing or no articles were found for the target date.`;\n}\n\nreturn [{\n  json: {\n    newsletter_content: combinedMarkdown,\n    date_processing: dateInfo,\n    content_cleaning_stats: {\n      total_articles: totalArticles,\n      total_words: totalWords,\n      original_characters: totalOriginalChars,\n      cleaned_characters: totalCleanedChars,\n      overall_reduction: `${overallReduction}%`,\n      sources_processed: sources\n    },\n    statistics: {\n      total_articles: totalArticles,\n      total_words: totalWords,\n      date_range: { start: targetDate, end: targetDate },\n      sources_processed: sources,\n      processing_date: new Date().toISOString(),\n      content_cleaning_enabled: true\n    }\n  }\n}];"
      },
      "id": "60db203d-9d45-4fad-bbc6-bc5d2e412b42",
      "name": "Combine into Newsletter",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -448,
        112
      ]
    },
    {
      "parameters": {
        "jsCode": "// Update tracking file with latest run information\nconst statistics = $input.first().json.statistics;\nconst originalTracking = $('Calculate Date Range').first().json.tracking_data;\n\nconst updatedTracking = {\n  last_successful_run: new Date().toISOString(),\n  last_processed_date: statistics.date_range.end,\n  files_processed: statistics.total_articles,\n  workflow_version: \"1.0\",\n  last_run_statistics: statistics\n};\n\nreturn [{\n  json: {\n    tracking_update: updatedTracking,\n    newsletter_content: $input.first().json.newsletter_content,\n    statistics: statistics\n  }\n}];"
      },
      "id": "bdefbbfd-04d1-47b4-80a5-9afe35c75369",
      "name": "Prepare Tracking Update",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -224,
        112
      ]
    },
    {
      "parameters": {
        "operation": "upload",
        "bucketName": "n8n-ai-news-stories",
        "fileName": "newsletter-automation-last-run.json",
        "binaryData": false,
        "fileContent": "={{ JSON.stringify($json.tracking_update, null, 2) }}",
        "additionalFields": {}
      },
      "id": "ab70e68f-c782-45a7-a8e2-65777054b6c1",
      "name": "Update Tracking File",
      "type": "n8n-nodes-base.s3",
      "typeVersion": 1,
      "position": [
        0,
        0
      ],
      "credentials": {
        "s3": {
          "id": "WRnQEZaYQvFm8YY3",
          "name": "Cloudflare R2 S3 Format Datalake"
        }
      }
    },
    {
      "parameters": {
        "operation": "upload",
        "bucketName": "n8n-ai-news-stories",
        "fileName": "={{ 'newsletter-combined-' + $json.statistics.processing_date.split('T')[0] + '.md' }}",
        "binaryData": false,
        "fileContent": "={{ $json.newsletter_content }}",
        "additionalFields": {}
      },
      "id": "0b6da435-918d-4930-9dbd-316555b13f49",
      "name": "Save Combined Newsletter",
      "type": "n8n-nodes-base.s3",
      "typeVersion": 1,
      "position": [
        0,
        208
      ],
      "credentials": {
        "s3": {
          "id": "WRnQEZaYQvFm8YY3",
          "name": "Cloudflare R2 S3 Format Datalake"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "Weekly Newsletter Trigger": {
      "main": [
        [
          {
            "node": "Initialize Date Processing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Manual Trigger (Testing/Override)": {
      "main": [
        [
          {
            "node": "Initialize Date Processing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Initialize Date Processing": {
      "main": [
        [
          {
            "node": "Fetch Last Run Tracking",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Last Run Tracking": {
      "main": [
        [
          {
            "node": "Calculate Date Range",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculate Date Range": {
      "main": [
        [
          {
            "node": "Split Date Prefixes",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Date Prefixes": {
      "main": [
        [
          {
            "node": "List Files by Date",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "List Files by Date": {
      "main": [
        [
          {
            "node": "Filter & Parse Markdown Files",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter & Parse Markdown Files": {
      "main": [
        [
          {
            "node": "Filter Files by Date Range",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter Files by Date Range": {
      "main": [
        [
          {
            "node": "Download Markdown Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Markdown Content": {
      "main": [
        [
          {
            "node": "Parse Content & Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Content & Metadata": {
      "main": [
        [
          {
            "node": "Aggregate All Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate All Content": {
      "main": [
        [
          {
            "node": "Combine into Newsletter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine into Newsletter": {
      "main": [
        [
          {
            "node": "Prepare Tracking Update",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Tracking Update": {
      "main": [
        [
          {
            "node": "Update Tracking File",
            "type": "main",
            "index": 0
          },
          {
            "node": "Save Combined Newsletter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "a86cd0b9-47fd-4d3e-8844-97c1002ab273",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "d735d77f21fd4aef6b73e3673b1ecc97bb1c1f558cf83cdb9413cefd83cbd75c"
  },
  "id": "bqfkxzc5vqPrv7JU",
  "tags": [
    {
      "createdAt": "2025-09-20T19:12:46.803Z",
      "updatedAt": "2025-09-20T19:12:46.803Z",
      "id": "RdvXnBOO6BbftY0g",
      "name": "RSS"
    },
    {
      "createdAt": "2025-09-19T22:34:09.163Z",
      "updatedAt": "2025-09-19T22:34:09.163Z",
      "id": "a58pFV5Wcl0MIzkr",
      "name": "Newsletter"
    }
  ]
}